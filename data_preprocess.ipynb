{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEARCH NAIVE CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "0.9166666666666666\n",
      "0.72\n",
      "0.8888888888888888\n",
      "0.8888888888888888\n",
      "0.9285714285714286\n",
      "0.8181818181818182\n",
      "0.7692307692307693\n",
      "0.8571428571428571\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.72\n",
      "1.0\n",
      "0.7272727272727273\n",
      "1.0\n",
      "0.8076923076923077\n",
      "1.0\n",
      "1.0\n",
      "0.7142857142857143\n",
      "0.3333333333333333\n",
      "1.0\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.8571428571428571\n",
      "1.0\n",
      "1.0\n",
      "0.9\n",
      "0.875\n",
      "0.8333333333333334\n",
      "0.8181818181818182\n",
      "1.0\n",
      "0.8333333333333334\n",
      "0.75\n",
      "0.5555555555555556\n",
      "1.0\n",
      "1.0\n",
      "0.8571428571428571\n",
      "1.0\n",
      "0.7586206896551724\n",
      "1.0\n",
      "1.0\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.5714285714285714\n",
      "0.75\n",
      "0.5614035087719298\n",
      "1.0\n",
      "0.95\n",
      "0.4878048780487805\n",
      "0.8505747126436781\n",
      "0.5263157894736842\n",
      "0.7209302325581395\n",
      "0.8571428571428571\n",
      "0.6\n",
      "0.46153846153846156\n",
      "0.8888888888888888\n",
      "0.5925925925925926\n",
      "0.7777777777777778\n",
      "0.782608695652174\n",
      "0.8518518518518519\n",
      "0.8125\n",
      "0.8\n",
      "1.0\n",
      "0.8518518518518519\n",
      "0.75\n",
      "0.7941176470588235\n",
      "1.0\n",
      "0.7857142857142857\n",
      "1.0\n",
      "0.8571428571428571\n",
      "0.7777777777777778\n",
      "1.0\n",
      "1.0\n",
      "0.5625\n",
      "0.875\n",
      "1.0\n",
      "0.7692307692307693\n",
      "0.8666666666666667\n",
      "0.8181818181818182\n",
      "0.9230769230769231\n",
      "0.7142857142857143\n",
      "0.8636363636363636\n",
      "1.0\n",
      "0.7307692307692307\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "1.0\n",
      "0.7719298245614035\n",
      "0.6363636363636364\n",
      "0.8461538461538461\n",
      "0.8888888888888888\n",
      "1.0\n",
      "0.975\n",
      "0.7407407407407407\n",
      "0.6785714285714286\n",
      "1.0\n",
      "0.8918918918918919\n",
      "0.8070175438596491\n",
      "1.0\n",
      "0.7625\n",
      "0.75\n",
      "0.65625\n",
      "1.0\n",
      "0.7692307692307693\n",
      "0.8846153846153846\n",
      "0.6185567010309279\n",
      "1.0\n",
      "0.95\n",
      "0.88\n",
      "1.0\n",
      "0.6782608695652174\n",
      "0.6666666666666666\n",
      "0.6635514018691588\n",
      "1.0\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.8837209302325582\n",
      "0.5\n",
      "0.6126760563380281\n",
      "0.6423841059602649\n",
      "0.5952380952380952\n",
      "0.8823529411764706\n",
      "0.7714285714285715\n",
      "0.5641025641025641\n",
      "0.6296296296296297\n",
      "0.6052631578947368\n",
      "0.8615384615384616\n",
      "0.6097560975609756\n",
      "0.7368421052631579\n",
      "0.6206896551724138\n",
      "0.811965811965812\n",
      "0.672566371681416\n",
      "0.6818181818181818\n",
      "0.9523809523809523\n",
      "0.7681159420289855\n",
      "0.625\n",
      "1.0\n",
      "1.0\n",
      "0.5740740740740741\n",
      "0.8415841584158416\n",
      "0.5421686746987951\n",
      "0.7619047619047619\n",
      "1.0\n",
      "0.8148148148148148\n",
      "0.9310344827586207\n",
      "0.8333333333333334\n",
      "0.72\n",
      "0.7222222222222222\n",
      "1.0\n",
      "0.7704918032786885\n",
      "0.8490566037735849\n",
      "0.7857142857142857\n",
      "0.9565217391304348\n",
      "0.8163265306122449\n",
      "0.7714285714285715\n",
      "0.6530612244897959\n",
      "0.7857142857142857\n",
      "ACCURACY Macro\n",
      "0.8196039636301313\n",
      "ACCURACY Micro\n",
      "0.7379270853216263\n"
     ]
    }
   ],
   "source": [
    "output_file = r'data/train_data.json'\n",
    "\n",
    "error_data = []\n",
    "micro_class_true = 0\n",
    "micro_class_predict = 0\n",
    "with open(output_file, encoding='utf-8-sig', mode='r') as f:\n",
    "    json_file = json.load(f)\n",
    "    for batch in json_file:\n",
    "        micro_class_true +=  batch['clusters']\n",
    "        micro_class_predict += len(batch['answers']) \n",
    "        accuracy = batch['clusters'] / len(batch['answers'])\n",
    "        error_data.append(accuracy)\n",
    "        print(accuracy)\n",
    "\n",
    "print('ACCURACY Macro')\n",
    "print(sum(error_data) / len(error_data))\n",
    "print('ACCURACY Micro')\n",
    "print(micro_class_true / micro_class_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEVENSHTEIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def cluster_similar_answers(json_data, similarity_threshold=0.63):\n",
    "    \"\"\"\n",
    "    Кластеризация похожих ответов на основе сходства по Левенштейну и агрегирование их количества.\n",
    "    Эта функция группирует похожие ответы из JSON-структуры на основе порога сходства Левенштейна.\n",
    "    Ответы с коэффициентом сходства, равным или превышающим пороговое значение, будут сгруппированы в один кластер.\n",
    "    Функция также агрегирует значения 'count' для ответов внутри каждого кластера.\n",
    "\n",
    "    Args:\n",
    "        json_data (dict): Словарь, содержащий список ответов с ключами 'answer' и 'count'.\n",
    "        similarity_threshold (float, optional): Порог сходства Левенштейна для кластеризации.\n",
    "            Ответы с коэффициентом сходства >= similarity_threshold будут сгруппированы вместе. По умолчанию 0.63.\n",
    "\n",
    "    Return:\n",
    "        dict: Словарь, ключами которого являются имена кластеров, а значениями - списки словарей с ключами\n",
    "            ключами 'answer' и 'count' для сгруппированных ответов.\n",
    "    \"\"\"\n",
    "    answers = json_data['answers']\n",
    "    clusters = {}\n",
    "    cluster_names = {}\n",
    "    \n",
    "    for i, answer1 in enumerate(answers):\n",
    "        answer1 = answer1['answer']\n",
    "        cluster_name = None\n",
    "        \n",
    "        for name, answer2 in cluster_names.items():\n",
    "            similarity = Levenshtein.ratio(answer1, answer2)\n",
    "            if similarity >= similarity_threshold:\n",
    "                cluster_name = name\n",
    "                break\n",
    "        \n",
    "        if cluster_name is None:\n",
    "            # Создаем новый кластер, если не нашли подходящий\n",
    "            cluster_name = i\n",
    "        \n",
    "        clusters.setdefault(cluster_name, []).append(answer1)\n",
    "        cluster_names[cluster_name] = max(cluster_names.get(cluster_name, ''), answer1, key=lambda x: Levenshtein.ratio(answer1, x))\n",
    "\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY Macro\n",
      "0.884772382407369\n",
      "ACCURACY Micro\n",
      "0.9829280910501811\n"
     ]
    }
   ],
   "source": [
    "output_file = r'data/train_data.json'\n",
    "\n",
    "error_data = []\n",
    "micro_class_true = 0\n",
    "micro_class_predict = 0\n",
    "with open(output_file, encoding='utf-8-sig', mode='r') as f:\n",
    "    json_file = json.load(f)\n",
    "    for batch in json_file:\n",
    "        lev_clusters = len(cluster_similar_answers(batch, similarity_threshold=0.58))\n",
    "        micro_class_true += batch['clusters']\n",
    "        micro_class_predict += lev_clusters\n",
    "        accuracy = min(batch['clusters'], lev_clusters) / max(batch['clusters'], lev_clusters)\n",
    "        error_data.append(accuracy)\n",
    "        # print(accuracy)\n",
    "\n",
    "print('ACCURACY Macro')\n",
    "print(sum(error_data) / len(error_data))\n",
    "print('ACCURACY Micro')\n",
    "print(min(micro_class_true, micro_class_predict) / max(micro_class_true, micro_class_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing necessary libs..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Goldian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " Starting filtering..\n",
      "Working with file data/train_data.json \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mprocessing\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m processing\u001b[39m.\u001b[39;49mfilter(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata/train_data.json\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata/proccesing_train.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\fast_dev\\hackathon_cp\\processing.py:79\u001b[0m, in \u001b[0;36mfilter\u001b[1;34m(OLDFILE_PATH, NEWFILE_PATH)\u001b[0m\n\u001b[0;32m     76\u001b[0m         outline \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([word \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m outline\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop_words])\n\u001b[0;32m     78\u001b[0m         \u001b[39m# Contextual Lemmatisation by pymystem3\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m         outline \u001b[39m=\u001b[39m lemmatize_sentence(outline)\n\u001b[0;32m     81\u001b[0m outfile\u001b[39m.\u001b[39mwrite(json\u001b[39m.\u001b[39mdumps(infile, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m))\n\u001b[0;32m     82\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDone - \u001b[39m\u001b[39m{\u001b[39;00mNEWFILE_PATH\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\fast_dev\\hackathon_cp\\processing.py:19\u001b[0m, in \u001b[0;36mlemmatize_sentence\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize_sentence\u001b[39m(text) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m---> 19\u001b[0m     lemmas \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mlemmatize(text)\n\u001b[0;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(lemmas)\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\Goldian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymystem3\\mystem.py:265\u001b[0m, in \u001b[0;36mMystem.lemmatize\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[39mMake morphology analysis for a text and return list of lemmas.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39m:rtype:         list\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m need_encode \u001b[39m=\u001b[39m (sys\u001b[39m.\u001b[39mversion_info[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m))\n\u001b[1;32m--> 265\u001b[0m infos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49manalyze(text)\n\u001b[0;32m    266\u001b[0m lemmas \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lemma, infos)))\n\u001b[0;32m    268\u001b[0m \u001b[39mif\u001b[39;00m need_encode \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Goldian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymystem3\\mystem.py:250\u001b[0m, in \u001b[0;36mMystem.analyze\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    248\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[0;32m    249\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m text\u001b[39m.\u001b[39msplitlines():\n\u001b[1;32m--> 250\u001b[0m     result\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_analyze_impl(line))\n\u001b[0;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Goldian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymystem3\\mystem.py:313\u001b[0m, in \u001b[0;36mMystem._analyze_impl\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_procin\u001b[39m.\u001b[39mwrite(text)\n\u001b[0;32m    311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_procin\u001b[39m.\u001b[39mwrite(_NL)\n\u001b[1;32m--> 313\u001b[0m out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_proc\u001b[39m.\u001b[39;49mcommunicate()\n\u001b[0;32m    314\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_proc \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[39m#obj = json.loads(out)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Goldian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[0;32m   1210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Goldian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1626\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[39m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1623\u001b[0m \u001b[39m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1624\u001b[0m \u001b[39m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1626\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdout_thread\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_remaining_time(endtime))\n\u001b[0;32m   1627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m   1628\u001b[0m         \u001b[39mraise\u001b[39;00m TimeoutExpired(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mc:\\Users\\Goldian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1111\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[0;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Goldian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[0;32m   1133\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import processing\n",
    "\n",
    "processing.filter(r'data/train_data.json', r'data/proccesing_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2003544130.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    INPUT_FILE_PATH =\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE_PATH = r'data/train_data.json'\n",
    "OUTPUT_FILE_PATH = r'data/predict_train.json'\n",
    "\n",
    "data = []\n",
    "\n",
    "# Вход и обучение\n",
    "with open(INPUT_FILE_PATH, encoding='utf-8-sig') as json_file:\n",
    "    for batch in json_file:\n",
    "        for answer in batch['answers']:\n",
    "        answer = batch['answers']['answer']\n",
    "        sentiment = batch['answers']['sentiment']\n",
    "        # ЗАСУНЬ СЮДА МОДЕЛЬ\n",
    "\n",
    "        batch['answers']['answer'] = \n",
    "        batch['answers']['sentiment'] =\n",
    "\n",
    "        #\n",
    "\n",
    "        data.append(batch)\n",
    "\n",
    "# Выход и сохранение\n",
    "with open(OUTPUT_FILE_PATH, encoding='utf-8-sig') as f:\n",
    "    f.write(json.dumps(data, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
